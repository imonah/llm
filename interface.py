import gradio as gr
import pandas as pd
import sqlite3
import os
import shutil
import requests
from urllib.parse import urlparse
from bs4 import BeautifulSoup
import trafilatura
import tempfile
from pathlib import Path
from qa_chain import ask, save_chat_history_to_db
import embed_and_index

# üëâ –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–¥–Ω—É —Å–µ—Å—Å–∏—é (–º–æ–∂–Ω–æ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID)
session_id = "default"

feedback_data = []
chunk_preview_df = pd.DataFrame()

def ask_with_feedback(query):
    response = ask(query, session_id=session_id)
    feedback_data.append({"question": query, "response": response})
    return response

def save_feedback():
    df = pd.DataFrame(feedback_data)
    df.to_csv("feedback_log.csv", index=False)
    return "–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ feedback_log.csv"

def save_chat_history():
    conn = sqlite3.connect("chat_memory.db")
    save_chat_history_to_db(conn, session_id=session_id)
    conn.close()
    return "–ò—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ chat_memory.db"

def process_and_index_content(content, source_name, source_type='text'):
    """Process and index content from any source (file or URL)"""
    temp_path = None
    try:
        # Ensure the data directory exists
        data_dir = "data"
        os.makedirs(data_dir, exist_ok=True)
        
        # Create a temporary file in the data directory
        with tempfile.NamedTemporaryFile(
            dir=data_dir,
            delete=False, 
            suffix=f".{source_type}",
            mode='wb' if isinstance(content, bytes) else 'w',
            encoding=None if isinstance(content, bytes) else 'utf-8'
        ) as temp_file:
            temp_path = temp_file.name
            if isinstance(content, bytes):
                temp_file.write(content)
            else:
                temp_file.write(content)
        
        print(f"üîç –í—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª —Å–æ–∑–¥–∞–Ω: {temp_path}")
        
        # Index the temporary file with explicit data_dir
        texts, preview = embed_and_index.index_all_data(
            file_path=temp_path, 
            source_name=source_name,
            data_dir=data_dir
        )
        
        return texts, preview
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {str(e)}", exc_info=True)
        return None, None
        
    finally:
        # Clean up the temporary file if it was created
        if temp_path and os.path.exists(temp_path):
            try:
                os.unlink(temp_path)
                print(f"üßπ –í—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª —É–¥–∞–ª–µ–Ω: {temp_path}")
            except Exception as e:
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª {temp_path}: {e}")

def extract_content_from_url(url):
    """Extract main content from a URL"""
    try:
        # Use trafilatura for better content extraction
        downloaded = trafilatura.fetch_url(url)
        if not downloaded:
            return None, "–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"
            
        # Extract main content
        content = trafilatura.extract(downloaded, include_links=False, include_tables=False)
        if not content:
            return None, "–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"
            
        # Get page title for the source name
        soup = BeautifulSoup(downloaded, 'html.parser')
        title = soup.title.string if soup.title else 'webpage'
        
        return content, title.strip()
    except Exception as e:
        print(f"Error extracting content from URL: {str(e)}")
        return None, f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ URL: {str(e)}"

def upload_file_and_index(file_obj):
    if file_obj is not None:
        try:
            # –ü–æ–ª—É—á–∞–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –∏ –ø—É—Ç—å –∫ –≤—Ä–µ–º–µ–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
            if isinstance(file_obj, dict):
                # –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–æ–≤–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞ —Ñ–∞–π–ª–∞ –æ—Ç Gradio
                filename = file_obj.get('name', 'unnamed_file')
                file_path = file_obj.get('path', '')
                temp_file_path = file_obj.get('tmp_path', '')
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
                if temp_file_path and os.path.exists(temp_file_path):
                    file_path = temp_file_path
            else:
                # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç–∞—Ä–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞
                filename = file_obj.name if hasattr(file_obj, 'name') else os.path.basename(str(file_obj))
                file_path = str(file_obj) if isinstance(file_obj, (str, os.PathLike)) else str(file_obj.name)
            
            print(f"üîç DEBUG: –ü–æ–ª—É—á–µ–Ω —Ñ–∞–π–ª: {filename}")
            print(f"üîç DEBUG: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É: {file_path}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
            if not os.path.exists(file_path):
                return f"‚ùå –û—à–∏–±–∫–∞: –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª {file_path} –Ω–µ –Ω–∞–π–¥–µ–Ω."
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
            original_size = os.path.getsize(file_path)
            print(f"üîç DEBUG: –†–∞–∑–º–µ—Ä –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞: {original_size} –±–∞–π—Ç")
            
            if original_size == 0:
                return f"‚ùå –û—à–∏–±–∫–∞: –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª {filename} –ø—É—Å—Ç–æ–π (0 –±–∞–π—Ç)."
            
            # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é data –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
            os.makedirs("data", exist_ok=True)
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—É—Ç—å –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è
            destination_path = os.path.join("data", os.path.basename(filename))
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–∏–Ω–∞—Ä–Ω–æ–µ —á—Ç–µ–Ω–∏–µ/–∑–∞–ø–∏—Å—å –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è
            try:
                with open(file_path, 'rb') as src, open(destination_path, 'wb') as dst:
                    shutil.copyfileobj(src, dst)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
                copied_size = os.path.getsize(destination_path)
                print(f"üîç DEBUG: –†–∞–∑–º–µ—Ä —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞: {copied_size} –±–∞–π—Ç")
                
                if copied_size == 0:
                    return f"‚ùå –û—à–∏–±–∫–∞: —Ñ–∞–π–ª {filename} —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω, –Ω–æ –ø–æ–ª—É—á–∏–ª—Å—è –ø—É—Å—Ç—ã–º."
                    
                if copied_size != original_size:
                    return f"‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –∏–∑–º–µ–Ω–∏–ª—Å—è –ø—Ä–∏ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–∏ ({original_size} ‚Üí {copied_size} –±–∞–π—Ç)."
                
                print(f"‚úÖ –§–∞–π–ª —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {destination_path}")
                
            except Exception as copy_error:
                print(f"üîç DEBUG: –û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–∏ —Ñ–∞–π–ª–∞: {copy_error}")
                return f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–∏ —Ñ–∞–π–ª–∞: {copy_error}"

        except Exception as e:
            print(f"üîç DEBUG: –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–∏: {e}")
            return f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}"

        # –ü–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è
        try:
            print(f"üîÑ –ù–∞—á–∏–Ω–∞—é –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ {filename}...")
            texts, _ = embed_and_index.index_all_data(return_preview=False)
            
            if not texts:
                return f"‚ö†Ô∏è –§–∞–π–ª {filename} –∑–∞–≥—Ä—É–∂–µ–Ω, –Ω–æ –Ω–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏."
            
            # –°–æ–∑–¥–∞–µ–º DataFrame —Å–æ –≤—Å–µ–º–∏ —á–∞–Ω–∫–∞–º–∏
            global chunk_preview_df
            chunk_preview_df = pd.DataFrame({
                "–ß–∞–Ω–∫": texts,
                "–ö–ª–∞—Å—Å": [classify_chunk(t) for t in texts]
            })
            
            return f"‚úÖ –§–∞–π–ª {filename} –∑–∞–≥—Ä—É–∂–µ–Ω –∏ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω. –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(texts)} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤."
            
        except Exception as index_error:
            print(f"üîç DEBUG: –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: {index_error}")
            return f"‚ö†Ô∏è –§–∞–π–ª {filename} –∑–∞–≥—Ä—É–∂–µ–Ω, –Ω–æ –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: {index_error}"
            
    return "‚ö†Ô∏è –§–∞–π–ª –Ω–µ –≤—ã–±—Ä–∞–Ω."

def classify_chunk(text):
    text_lower = text.lower()
    if "–æ—à–∏–±–∫–∞" in text_lower or "exception" in text_lower:
        return "–±–∞–≥"
    elif "log" in text_lower or "response" in text_lower:
        return "–ª–æ–≥"
    elif "—Ç–µ—Å—Ç" in text_lower or "–ø—Ä–æ–≤–µ—Ä–∫–∞" in text_lower:
        return "—Ç–µ—Å—Ç"
    elif "—Ç—Ä–µ–±–æ–≤–∞–Ω" in text_lower or "–¥–æ–ª–∂–µ–Ω" in text_lower:
        return "—Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ"
    return "–¥—Ä—É–≥–æ–µ"

def show_chunks():
    if not chunk_preview_df.empty:
        return chunk_preview_df
    return pd.DataFrame({"–ß–∞–Ω–∫": [], "–ö–ª–∞—Å—Å": []})

def process_url(url):
    """Process a URL and index its content"""
    if not url:
        return "‚ö†Ô∏è –í–≤–µ–¥–∏—Ç–µ URL –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏"
        
    try:
        # Validate URL
        parsed = urlparse(url)
        if not all([parsed.scheme, parsed.netloc]):
            return "‚ö†Ô∏è –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π URL"
            
        # Extract content from URL
        content, title = extract_content_from_url(url)
        if not content:
            return f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –ø–æ URL: {url}"
            
        # Process and index the content
        source_name = f"URL: {title} ({url})"
        texts, _ = process_and_index_content(content, source_name, 'txt')
        
        if not texts:
            return f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å {url}"
            
        # Create DataFrame with all chunks
        global chunk_preview_df
        chunk_preview_df = pd.DataFrame({
            "–ß–∞–Ω–∫": texts,
            "–ö–ª–∞—Å—Å": [classify_chunk(t) for t in texts]
        })
        
        return f"‚úÖ –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å {url} –∑–∞–≥—Ä—É–∂–µ–Ω–æ –∏ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ. –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(texts)} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤."
        
    except Exception as e:
        print(f"Error processing URL: {str(e)}")
        return f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ URL: {str(e)}"

with gr.Blocks() as demo:
    gr.Markdown("# ü§ñ QA-–ø–æ–º–æ—â–Ω–∏–∫ —Å –ø–∞–º—è—Ç—å—é, –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–µ–π –∏ –ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä–æ–º")

    with gr.Row():
        query = gr.Textbox(label="–í–æ–ø—Ä–æ—Å –ø–æ –±–∞–≥–∞–º, –ª–æ–≥–∞–º, —Ç–µ—Å—Ç–∞–º")
        answer = gr.Textbox(label="–û—Ç–≤–µ—Ç")
    ask_btn = gr.Button("–°–ø—Ä–æ—Å–∏—Ç—å")

    with gr.Row():
        feedback_btn = gr.Button("üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç–∑—ã–≤—ã")
        save_chat_btn = gr.Button("üìú –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞")

    with gr.Row():
        with gr.Column():
            file_input = gr.File(
                label="–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª", 
                file_types=[".txt", ".docx", ".pdf", ".md", ".csv", ".xlsx"],
                file_count="single"
            )
            file_status = gr.Textbox(label="–°—Ç–∞—Ç—É—Å –∑–∞–≥—Ä—É–∑–∫–∏", interactive=False)
        
        with gr.Column():
            url_input = gr.Textbox(label="–ò–ª–∏ –≤–≤–µ–¥–∏—Ç–µ URL –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ")
            url_button = gr.Button("üì• –ó–∞–≥—Ä—É–∑–∏—Ç—å —Å URL")
            url_status = gr.Textbox(label="–°—Ç–∞—Ç—É—Å –∑–∞–≥—Ä—É–∑–∫–∏ URL", interactive=False)

    preview_btn = gr.Button("üîç –ü–æ–∫–∞–∑–∞—Ç—å —á–∞–Ω–∫–∏")
    chunk_table = gr.Dataframe(label="–ß–∞–Ω–∫–∏ –∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è")

    ask_btn.click(fn=ask_with_feedback, inputs=query, outputs=answer)
    feedback_btn.click(fn=save_feedback, outputs=gr.Textbox())
    save_chat_btn.click(fn=save_chat_history, outputs=gr.Textbox())
    file_input.change(fn=upload_file_and_index, inputs=file_input, outputs=file_status)
    url_button.click(fn=process_url, inputs=url_input, outputs=url_status)
    preview_btn.click(fn=show_chunks, outputs=chunk_table)

demo.launch()
